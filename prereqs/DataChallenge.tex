
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{2026 Data Challenge - Vital Statistics}  \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%================================================================
\section{Problem Description}\label{sec:Problem}
%================================================================
Your team is part of a consultancy supporting a planning commission for the State of Texas.  The commission is planning budgetary requirements for various State services in 2030.  The commission requests the following:
\begin{itemize}
	\item Projections of underweight newborns by county in Texas.
	\item Projections of newborn mortality by county in Texas. According to the CDC, a stillbirth is classified as either early, late, or term. An early stillbirth is a fetal death occurring between 20 and 27 completed weeks of pregnancy. A late stillbirth occurs between 28 and 36 completed pregnancy weeks. A term stillbirth occurs between 37 or more completed pregnancy weeks.
	\item Identification of the socioeconomic factors associated with these two outcomes.
	\item Comparison to other states.
\end{itemize}

Your team will produce an executive report accompanied by an appendix of technical material.

%================================================================
\section{Data Description}
%================================================================
The commission has approved specific data sources for this analysis. You can only use approved data available at \href{https://drive.google.com/drive/folders/1oq2yuKgBPOAp4wwRngMAI5b_tvVDlNvm}{this hyperlink}.

\textbf{National Center for Health Statistics (NCHS)}: Since 1969, all births recorded in the US are available as digital records from the NCHS, from the Centers for Disease Control and Prevention (CDC). The date and time of birth is publicly available only between 1969 and 1988; starting in 1989, only the week of birth is recorded. %Why is the date and time of birth no longer recorded? %\QA
The NCHS keeps records of place of birth, assistance during delivery (at home, with doctors, with midwives), level of education of the parents, place of residence, weight at birth, number of weeks of gestation, number of siblings, birth order, etc. In total, over 100 variables are recorded. You have access to records form 1969 to 1988.

\textbf{Surveillance, Epidemiology, and End Results Program (SEER)}: The U.S. Census Bureau annually releases unabridged population estimates for five-year age groups and race at the county level. The Census Bureau does not release bridged race estimates by single year of age at the county level due to concerns about the reliability of these estimates. However, these estimates are provided to the National Cancer Institute through SEER to meet programmatic needs such as the creation of age groupings that differ from the standard groupings used by the Census Bureau. Users of the single-year-of-age county-level interpolated race population estimates should carefully consider the limited reliability of these estimates. County-level population files with 19 age groups ($<$1, 1-4, ..., 80-84, 85+) and with 86 single-year age groups ($<$1, 1, 2, ..., 84, 85+) are provided.

\textbf{Socioeconomic Data and Applications Center (SEDAC)}: SEDAC, the Socioeconomic Data and Applications Center, is one of the Distributed Active Archive Centers (DAACs) in the Earth Observing System Data and Information System (EOSDIS) of the U.S. National Aeronautics and Space Administration (NASA). SEDAC contains georeferenced U.S. county-level population projections, total and by sex, race and age, based on shared socioeconomic pathways (SSPs). This data set, produced by Mathew E. Hauer, consists of county-level population projection scenarios of population in five-year intervals for all U.S. counties for the period 2020 - 2100. Obtain the data description from \href{https://doi.org/10.1038/sdata.2019.5}{https://doi.org/10.1038/sdata.2019.5}.

The NCHS data set covers from 1969 through 1986; it provides individual birth data. The SEER data set provides age-bracketed population estimates from 1969 to 2020. Since for this exercise we do not have birth data beyond 1986, you will have to use the SEER data to infer births in the period 1987-2020; alternatively, you could go to the NCHS source and obtain more recent data, however the NCHS data is complex and downloading additional years is not advised in the short time available to complete the Rowdy Datathon (but we will not stop you). The SEDAC data has total population estimates per county from 2020 through 2100 categorized in four ethnicities: Hispanic, white, black, and other. A viable sequence of analysis is NCHS $\rightarrow$ SEER $\rightarrow$ SEDAC.

%================================================================
\section{Identifying Underweight Cutoff Points}
%================================================================
The CDC offers a data table of infant weight for age, available at: \\ \href{https://www.cdc.gov/growthcharts/data/zscore/wtageinf.xls}{https://www.cdc.gov/growthcharts/data/zscore/wtageinf.xls} \\ You can extract from this table the information related to weight at birth.

The Excel file \texttt{wtageinf.xls} contains the LMS parameters and selected percentile values needed to compute exact percentiles and $z$-scores for anthropometric measurements. The parameters are provided by sex (1 = male, 2 = female) and by single month of age. Age is listed at the half-month point representing the entire month (e.g., 1.5 months corresponds to 1.0--1.99 months). The only exception is birth, which represents the point at birth.

The LMS method summarizes the distribution of a measurement at a given age using three parameters:
\begin{itemize}
    \item $L$: the Box--Cox power transformation,
    \item $M$: the median,
    \item $S$: the generalized coefficient of variation.
\end{itemize}
These parameters allow computation of both percentiles and $z$-scores.

To obtain the measurement value $X$ corresponding to a given $z$-score $Z$ (or percentile), use:

\[
X = M(1 + LSZ)^{1/L}, \quad L \neq 0
\]

\[
X = M \exp(SZ), \quad L = 0
\]
%
where $L$, $M$, and $S$ are taken from the Excel row corresponding to the child's age (in months) and sex. The $z$-score corresponding to common percentiles is:
%
\[
\begin{aligned}
-1.881 &\leftrightarrow 3^\text{rd} \\
-1.645 &\leftrightarrow 5^\text{th} \\
-1.282 &\leftrightarrow 10^\text{th} \\
-0.674 &\leftrightarrow 25^\text{th} \\
0      &\leftrightarrow 50^\text{th}
\end{aligned}
\]
%
\paragraph{Example:}
For a 9-month-old male, the \texttt{WTAGEINF} table gives:
\[
L = -0.1600954, \quad
M = 9.476500305, \quad
S = 0.11218624.
\]
Using $Z = -1.645$ (5th percentile), the cutoff is:
\[
X = 7.90 \text{ kg}.
\]
%
This value represents the 5th percentile weight-for-age and can be used as an underweight threshold if the 5th percentile definition is adopted.
%
\paragraph{Computing a Z-Score from a Measurement:}
%
To obtain the $z$-score corresponding to a given measurement $X$:

\[
Z = \frac{(X/M)^L - 1}{LS}, \quad L \neq 0
\]

\[
Z = \frac{\ln(X/M)}{S}, \quad L = 0.
\]
%
The corresponding percentile is then obtained from the standard normal distribution.
%
\paragraph{Example:}
For a 9-month-old male weighing 9.7 kg:
%
\[
Z = 0.207,
\]
%
which corresponds approximately to the 58th percentile.

\paragraph{Identifying Underweight Cutoff Points in Excel:}
To identify an underweight threshold in the Excel file:
%
\begin{enumerate}
    \item Filter the data by sex (1 = male, 2 = female).
    \item Locate the row corresponding to the child's age in months.
    \item Identify the desired cutoff percentile (e.g., 5th or 3rd percentile column).
    \item Alternatively, compute the exact cutoff using the LMS formula above.
\end{enumerate}
%
A child is classified as underweight if their measured value falls below the selected percentile cutoff (e.g., below the 5th percentile or below $Z=-2$, depending on the chosen clinical definition).

If finer age resolution is required, linear interpolation between adjacent months may be applied to the $L$, $M$, and $S$ parameters prior to computation.

%================================================================
\section{Data Files}
%================================================================

\begin{table}[htbp]
  \centering
  \caption{File sizes. If you have limited storage, plan your analysis in stages.}
    \begin{tabular}{|l|r|l|l|}
    \toprule
    DATA SET & \multicolumn{1}{l|}{FILE} & ZIPPED & UNZIPPED \\
    \midrule
    NCHS  & \multicolumn{1}{l|}{US1969-1986.zip} & 2.7 GB & 22.8 GB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{natalityConfBackup\_PostgreSQL.sql} & 2.42 GB & 25 GB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{US1969.zip} & 32.6 MB & 381 MB \\
    \midrule
    SEDAC & \multicolumn{1}{l|}{hauer\_county\_NH\_pop\_SSPs.xlsx} & N/A   & 15.1 MB \\
    \midrule
    SEER  & \multicolumn{1}{l|}{SEER Data Dictionary.pdf} &       & 73 KB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{tx.1969\_2020.19ages.adjusted.txt.gz} & 5.3 MB & 35 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{tx.1969\_2020.singleages.adjusted.txt.gz} & 18.8 BM & 19 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{tx.1990\_2020.19ages.adjusted.txt.gz} & 6.5 MB & 6 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{tx.1990\_2020.singleages.adjusted.txt.gz} & 20.9 MB & 21 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{us.1969\_2020.19ages.adjusted.txt.gz} & 66.7 MB & 430 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{us.1969\_2020.singleages.adjusted.txt.gz} & 238.8 MB & 1.6 GB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{us.1990\_2020.19ages.adjusted.txt.gz} & 76.7 MB & 520 MB \\
\cmidrule{2-4}          & \multicolumn{1}{l|}{us.1990\_2020.singleages.adjusted.txt.gz} & 246.3 MB & 1.8 GB \\
    \midrule
    TOTAL  &       & 5.7 GB & 52 GB \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

%================================================================
\section{Criteria}
%================================================================
Results will be evaluated according to requirements set by the commission:
\begin{itemize}
	\item \textbf{Compelling presentation}: You must enable the commission to share your numerical and graphical results directly with legislators and citizens through executive summaries. This lay audience should find your summaries and implications to be understandable and convincing.  Express your results in ways that can be acted on to plan e.g. funding of schools, care for the elderly, etc. The supporting documentation can be technical.
	\item \textbf{Analysis comprehension}: Before a single line of code is written, before a single byte of raw data is processed, you must be able to tell the story of what is the progression of steps that will be undertaken in analysis.
	\item \textbf{Sound technical methods}: You may cite the analyses of others, but the commission wants to see the methods that you have invented or adopted to calculate these projections (which should be accompanied by error bars, if possible).  The commision must have confidence in your results in order to present those results to others.
	\item \textbf{Awareness of the data context}: All data have bias. Before, during and after analysis, it is essential to identify biases in the data and articulate clearly how these biases influence all steps of analysis and interpretation.
	\item \textbf{Reproducible results}: You must enable the commission to have your results confirmed by an independent team.  That is, enable the independent team to replicate your results by describing your data and methods in detail.
\end{itemize}

% Table generated by Excel2LaTeX from sheet 'Sheet3'
\begin{table}[htbp]
  \centering
  \caption{Evaluation Criteria}
    \begin{tabular}{|p{22em}|r|}
    \toprule
    \textbf{CRITERION} & \multicolumn{1}{p{8em}|}{\textbf{\% WEIGHT}} \\
    \midrule
    1. Compelling presentation - Informative & 10\% \\
    \midrule
    2. Compelling presentation - Understandable & 10\% \\
    \midrule
    3. Analysis comprehension & 20\% \\
    \midrule
    4. Sound technical methods & 20\% \\
    \midrule
    5. Awareness of the data context & 20\% \\
    \midrule
    6. Reproducible results & 20\% \\
    \bottomrule
    \end{tabular}%
  \label{tab:addlabel}%
\end{table}%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Foundational Analysis Activities}  \newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%--------------------------------------------
\section{A single year of vital statistics}
%--------------------------------------------

A problem most people can relate to is demography. Millions of people are born in the US every year. Recording birth events is necessary for legal matters such as obtaining a driver's license or other forms of government-issued identification. However, recording, keeping, and using this information has challenges that exemplify many aspects of data analysis, as this exercise will demonstrate.

Since 1969, all births recorded in the US are available as digital records from the National Center for Health Statistics (NCHS) from the Centers for Disease Control and Prevention (CDC). Only between 1969 and 1988 the date and time of birth is publicly available; starting on 1989, only the week of birth is recorded. Why is the date and time of birth no longer recorded? \QA


The NCHS keeps records of place of birth, assistance during delivery (at home, with doctors, with midwives), level of education of the parents, place of residence, weight at birth, number of weeks of gestation, number of siblings, birth order, etc. In total, over 100 variables are recorded.

I have made available two files for you: a compressed file with birth records from 1969, and a data dictionary. The uncompressed data file is about 380 MB in size. The data is contained in a "flat file". This means that every line of text in this file is a continuous chain of characters. We must extract information from this type of files with a "dictionary" that tells us the beginning and ending columns of a given variable. Why was this format used? \QA


Please answer the following questions:
\begin{enumerate}
	\item How many live births occurred in Texas in 1969 from mothers residing in Texas?	\QA
	\begin{itemize}
		\item Bonus question: How would you visualize births from each state with respect to every other state?
	\end{itemize}
	\item Show graphically how the level of education of the mother is related to the birth order (1st born, second child, third, etc.)	 \QA
	\begin{itemize}
		\item Bonus question: How would you visualize each variable with respect to every other variable?
	\end{itemize}
\end{enumerate}

It is possible that you might not know how to answer some of these questions on first contact with this problem.

A simple program that can help you explore this file is

\BeginCode
f = open("US1969.dat", "r", encoding="cp1252")
counter = 0;
for x in f:
    if x[25] == "7" and x[26] ==  "4": # other conditions?
        counter = counter + 1
print(counter)
\end{verbatim}
\EndCode
%

The instruction \textit{encoding=``cp1252"} is necessary in non-Windows systems due the presence of single-byte character encoding of the Latin alphabet, used by default in the legacy components of Microsoft Windows for English and many European languages including Spanish, French, and German. If you remove this instruction, the following error might show up in non-Windows operating systems: ``'utf-8' codec can't decode byte...''

A common approach to extract information from flat files is by importing it into Excel. The ``\textit{Text Import Wizard}'' (typically shown as in Figure \ref{fig:Excel}) would guide you through the process of identifying variables by column. However, this results in a problem. Describe it. \QA

\begin{figure}[hb]
	\centering
		\includegraphics{../images/Excel.png}
	\caption{Excel's Import Wizard}
	\label{fig:Excel}
\end{figure}


